{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import sqlalchemy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "\n",
    "with open('auth.txt', 'r') as f:\n",
    "    keys = f.read().splitlines()\n",
    "PWD, USR, DB = keys\n",
    "\n",
    "SQLALCHEMY_DATABASE_URI = f\"mysql+pymysql://{USR}:{PWD}@{DB}\"\n",
    "\n",
    "Session = sessionmaker()\n",
    "engine = create_engine(SQLALCHEMY_DATABASE_URI)\n",
    "Session.configure(bind=engine)\n",
    "\n",
    "Base = declarative_base(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import Column, Integer, String, Date, Numeric, desc\n",
    "\n",
    "class VWPH(Base):\n",
    "    __tablename__ = 'vw_ph'\n",
    "    \n",
    "    study_id = Column(Integer)\n",
    "    site_id = Column(Integer)\n",
    "    site_name = Column(String)\n",
    "    ph_verb_start_year = Column(Integer)\n",
    "    ph_verb_end_year = Column(Integer)\n",
    "    ph_start_date = Column(Date)\n",
    "    ph_end_date = Column(Date)\n",
    "    ph_effective_date = Column(Date)\n",
    "    ph_id = Column(Integer, primary_key=True)\n",
    "    pulse_disturbance = Column(String)\n",
    "    pulse_intensity = Column(String)\n",
    "    land_use = Column(String)\n",
    "    land_use_intensity = Column(String)\n",
    "    source_habitat_description = Column(String)\n",
    "    managed_for_biodiversity = Column(String)\n",
    "    habitat_patch_area_unit = Column(String)\n",
    "    habitat_patch_area_value = Column(Numeric)\n",
    "    restoration_type = Column(String)\n",
    "    ff1 = Column(String)\n",
    "    ff2 = Column(String)\n",
    "    ff3 = Column(String)\n",
    "    crop = Column(String)\n",
    "    organic = Column(String)\n",
    "    aes = Column(String)\n",
    "    fragmentation_layout = Column(String)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Table('vw_ph', MetaData(bind=Engine(mysql+pymysql://sarav:***@LSCI-G78FG52:3306/predicts_2)), Column('study_id', Integer(), table=<vw_ph>), Column('site_id', Integer(), table=<vw_ph>), Column('site_name', String(), table=<vw_ph>), Column('ph_verb_start_year', Integer(), table=<vw_ph>), Column('ph_verb_end_year', Integer(), table=<vw_ph>), Column('ph_start_date', Date(), table=<vw_ph>), Column('ph_end_date', Date(), table=<vw_ph>), Column('ph_effective_date', Date(), table=<vw_ph>), Column('ph_id', Integer(), table=<vw_ph>, primary_key=True, nullable=False), Column('pulse_disturbance', String(), table=<vw_ph>), Column('pulse_intensity', String(), table=<vw_ph>), Column('land_use', String(), table=<vw_ph>), Column('land_use_intensity', String(), table=<vw_ph>), Column('source_habitat_description', String(), table=<vw_ph>), Column('managed_for_biodiversity', String(), table=<vw_ph>), Column('habitat_patch_area_unit', String(), table=<vw_ph>), Column('habitat_patch_area_value', Numeric(), table=<vw_ph>), Column('restoration_type', String(), table=<vw_ph>), Column('ff1', String(), table=<vw_ph>), Column('ff2', String(), table=<vw_ph>), Column('ff3', String(), table=<vw_ph>), Column('crop', String(), table=<vw_ph>), Column('organic', String(), table=<vw_ph>), Column('aes', String(), table=<vw_ph>), Column('fragmentation_layout', String(), table=<vw_ph>), schema=None)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VWPH.__table__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session()\n",
    "\n",
    "# Pull back results from vw_ph \n",
    "all_results = session.query(VWPH).filter(VWPH.site_id < 15).order_by(VWPH.site_id) \n",
    "\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- data has been loaded from here - no need to re-run cells above ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def roll_back(groups_2, variable):\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    for site, ph_period in groups_2.items():    \n",
    "        \n",
    "        # Grab a single site/multiple site records\n",
    "        period_iter = iter(ph_period)\n",
    "\n",
    "        # Initialise variables\n",
    "        running = True\n",
    "        start_elem = next(period_iter)\n",
    "\n",
    "        start_ph_id = start_elem.ph_id # might be replaced if earlier period has same value\n",
    "\n",
    "        start_date = start_elem.ph_start_date # might be replaced if earlier period has same value\n",
    "        effective_date = start_elem.ph_effective_date # Hang onto this so we know when-ish the ph change even occurred, might be replaced etc...\n",
    "\n",
    "        end_date = start_elem.ph_end_date # should stay the same, at least for this value of the variable\n",
    "        end_ph_id = start_elem.ph_id # ditto\n",
    "\n",
    "        while running:\n",
    "            try:\n",
    "                # Load the previous period\n",
    "                next_elem = next(period_iter)\n",
    "\n",
    "                # Previous pressure history period has the same variable value as the current ph period - keep going backwards\n",
    "                if (getattr(next_elem, variable) == getattr(start_elem, variable)) or (getattr(start_elem, variable) is None and getattr(next_elem, variable) is not None):\n",
    "                    start_elem = next_elem\n",
    "\n",
    "                    start_date = start_elem.ph_start_date # Shift the start date back: pressure state covers > 1 pressure history period\n",
    "                    effective_date = start_elem.ph_effective_date # ditto\n",
    "                    start_ph_id = start_elem.ph_id # ditto\n",
    "\n",
    "                # Previous period's ph variable has a different value than the current period, so we've traversed the current period \n",
    "                else:\n",
    "                    # Stash the details of this ph/variable combo\n",
    "                    results.append({'start_ph_id': start_ph_id, 'end_ph_id': end_ph_id, 'site_id': start_elem.site_id, 'variable_name': variable, 'variable_value': getattr(start_elem, variable), 'start_date': start_date,\n",
    "                                   'end_date': end_date, 'effective_date': effective_date, 'previous_value': getattr(next_elem, variable)})\n",
    "\n",
    "                    # Move onto the next period and reset the variables to reflect that this is a new start\n",
    "                    start_elem = next_elem\n",
    "\n",
    "                    start_date = start_elem.ph_start_date\n",
    "                    end_date = start_elem.ph_end_date\n",
    "\n",
    "                    effective_date = start_elem.ph_effective_date\n",
    "\n",
    "                    start_ph_id = start_elem.ph_id\n",
    "                    end_ph_id = start_elem.ph_id\n",
    "\n",
    "\n",
    "            # Last ph in the list (represents first record chronologically)\n",
    "            except StopIteration:\n",
    "                running = False\n",
    "                # Stash the results of the final period\n",
    "                results.append({'start_ph_id': start_ph_id, 'end_ph_id': end_ph_id, 'site_id': start_elem.site_id, 'variable_name': variable, 'variable_value': getattr(start_elem, variable), 'start_date': start_date, \n",
    "                                'end_date': end_date, 'effective_date': effective_date, 'previous_value': 'Unknown'})\n",
    "\n",
    "                \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "groups = {}\n",
    "uniquekeys = []\n",
    "\n",
    "# Groups into a 2D list, aggregated by site_id\n",
    "for k, g in groupby(all_results, lambda x: x.site_id):\n",
    "    groups[k] = sorted(list(g), key=lambda x: x.ph_start_date, reverse=True) \n",
    "    uniquekeys.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pressure history states we need to track:\n",
    "ph = ['land_use', 'land_use_intensity', 'source_habitat_description', 'managed_for_biodiversity', 'habitat_patch_area_unit', 'habitat_patch_area_value', 'restoration_type', \n",
    "      'ff1', 'ff2', 'ff3', 'crop', 'organic', 'aes', 'fragmentation_layout']\n",
    "\n",
    "# Place to stash the results before writing to db\n",
    "results = []\n",
    "\n",
    "for variable in ph:\n",
    "    results.extend(roll_back(groups, variable))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('test_all_ph.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PREDICTS2",
   "language": "python",
   "name": "predicts2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
